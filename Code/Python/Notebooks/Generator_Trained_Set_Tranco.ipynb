{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               1             google.com\n",
      "0              2           a-msedge.net\n",
      "1              3            youtube.com\n",
      "2              4           facebook.com\n",
      "3              5          microsoft.com\n",
      "4              6          amazonaws.com\n",
      "...          ...                    ...\n",
      "3576070  3576072         black-latte.eu\n",
      "3576071  3576073            lmd-inc.com\n",
      "3576072  3576074               yoow.com\n",
      "3576073  3576075               ckie.com\n",
      "3576074  3576076  hk-stanley-market.com\n",
      "\n",
      "[3576075 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('tranco_6JVNX.csv.gz', compression='gzip')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Domain\n",
      "0                 a-msedge.net\n",
      "1                  youtube.com\n",
      "2                 facebook.com\n",
      "3                microsoft.com\n",
      "4                amazonaws.com\n",
      "...                        ...\n",
      "3576071            lmd-inc.com\n",
      "3576072               yoow.com\n",
      "3576073               ckie.com\n",
      "3576074  hk-stanley-market.com\n",
      "3576075             google.com\n",
      "\n",
      "[3576076 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('1', axis=1)\n",
    "df = df.rename(columns={'google.com': 'Domain'})\n",
    "df.loc[df.index.max() + 1] = 'google.com'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n",
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n",
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n",
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n",
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n",
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n",
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n",
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n",
      "<ipython-input-3-aba5d43c0947>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Domain  TLD  Domain Name\n",
      "0          a-msedge.net  net     a-msedge\n",
      "1           youtube.com  com      youtube\n",
      "2          facebook.com  com     facebook\n",
      "3         microsoft.com  com    microsoft\n",
      "4         amazonaws.com  com    amazonaws\n",
      "...                 ...  ...          ...\n",
      "3039134  black-latte.eu   eu  black-latte\n",
      "3039135     lmd-inc.com  com      lmd-inc\n",
      "3039136        yoow.com  com         yoow\n",
      "3039137        ckie.com  com         ckie\n",
      "3039138      google.com  com       google\n",
      "\n",
      "[3039139 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tldextract\n",
    "import wordninja\n",
    "\n",
    "# Function to split a domain into meaningful keywords\n",
    "def split_domain_into_keywords(domain):\n",
    "    # Use tldextract to extract parts of the domain\n",
    "    extracted = tldextract.extract(domain)\n",
    "\n",
    "    # Get separated parts of the domain\n",
    "    #subdomain = extracted.subdomain\n",
    "    domain_name = extracted.domain\n",
    "    tld = extracted.suffix\n",
    "\n",
    "    # Split the domain into keywords using wordninja\n",
    "    #subdomain_keywords = wordninja.split(subdomain) if subdomain else []\n",
    "    #domain_keywords = wordninja.split(domain_name)\n",
    "\n",
    "    return {\n",
    "        #\"Subdomain Keywords\": subdomain_keywords,\n",
    "        #\"Domain Keywords\": domain_keywords,\n",
    "        \"TLD\": tld,\n",
    "        \"Domain Name\": domain_name\n",
    "    }\n",
    "\n",
    "batch_size = 500000\n",
    "results = []\n",
    "\n",
    "for batch_number, start in enumerate(range(0, len(df), batch_size), start=1):\n",
    "    end = start + batch_size\n",
    "    batch_df = df.iloc[start:end]\n",
    "\n",
    "    print(f\"Processing batch {batch_number}\")\n",
    "    \n",
    "    # Apply the function to the 'Domain' column and create additional columns\n",
    "    batch_df[['TLD', 'Domain Name']] = batch_df['Domain'].apply(split_domain_into_keywords).apply(pd.Series)\n",
    "\n",
    "    results.append(batch_df)\n",
    "\n",
    "# Concatenate the results into a new DataFrame\n",
    "df = pd.concat(results)\n",
    "\n",
    "# Filter the dataframe to keep only rows where the length of the element in the \"Domain Name\" column is less than or equal to 15\n",
    "df = df[df['Domain Name'].str.len() <= 15]\n",
    "\n",
    "# Reset the dataframe index to maintain row order\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "max_length = df['Domain Name'].str.len().max()\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Domain  TLD  Domain Name      domain_maxl\n",
      "0          a-msedge.net  net     a-msedge  a-msedge       \n",
      "1           youtube.com  com      youtube  youtube        \n",
      "2          facebook.com  com     facebook  facebook       \n",
      "3         microsoft.com  com    microsoft  microsoft      \n",
      "4         amazonaws.com  com    amazonaws  amazonaws      \n",
      "...                 ...  ...          ...              ...\n",
      "3039134  black-latte.eu   eu  black-latte  black-latte    \n",
      "3039135     lmd-inc.com  com      lmd-inc  lmd-inc        \n",
      "3039136        yoow.com  com         yoow  yoow           \n",
      "3039137        ckie.com  com         ckie  ckie           \n",
      "3039138      google.com  com       google  google         \n",
      "\n",
      "[3039139 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Suppose you have a DataFrame df with a 'Domain Name' column\n",
    "\n",
    "# Desired maximum length\n",
    "max_length = 15\n",
    "\n",
    "# Fill the domains with spaces to make them all the same length\n",
    "df['domain_maxl'] = df['Domain Name'].str.ljust(max_length)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length at position 0 : 15\n"
     ]
    }
   ],
   "source": [
    "position = 0  # Desired position\n",
    "domain0 = df.loc[position, 'domain_maxl']\n",
    "length = len(domain0)\n",
    "print(\"Length at position\", position, \":\", length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df['domain_maxl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The string has 3241748.2 characters.\n"
     ]
    }
   ],
   "source": [
    "length = len(text) / 15\n",
    "print(\"The string has\", length, \"characters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz0123456789-._ \n",
      "[' ', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Total chars: 40\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "alphabet = string.ascii_lowercase + \"0123456789-._ \"\n",
    "print(alphabet)\n",
    "\n",
    "chars = sorted(list(set(alphabet)))\n",
    "print(chars)\n",
    "print(\"Total chars:\", len(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 16208736\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - max_length, step):\n",
    "    sentences.append(text[i : i + max_length])\n",
    "    next_chars.append(text[i + max_length])\n",
    "print(\"Number of sequences:\", len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 16208736\n",
      "         sentences next_chars\n",
      "0  a-msedge                  \n",
      "1  sedge        yo          u\n",
      "2  ge        youtu          b\n",
      "3         youtube            \n",
      "4      youtube               \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the lists sentences and next_chars\n",
    "df1 = pd.DataFrame({'sentences': sentences, 'next_chars': next_chars})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df1.to_csv('datasec.csv', index=False)\n",
    "\n",
    "# Verify the length of the DataFrame and its structure\n",
    "print(\"Number of sequences:\", len(df1))\n",
    "print(df1.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the new model with a convolutional layer and an LSTM layer\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(max_length, len(chars))),\n",
    "    layers.Conv1D(128, kernel_size=3, activation='relu'),  # Convolutional layer\n",
    "    layers.MaxPooling1D(pool_size=2),  # Optional max pooling layer to reduce dimensionality\n",
    "    layers.LSTM(128),  # LSTM layer\n",
    "    layers.Dense(len(chars), activation='softmax')  # Output dense layer\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer and categorical_crossentropy loss function\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # Helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-32b89a27f457>:16: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences_batch), max_length, len(chars)), dtype=np.bool)\n",
      "<ipython-input-15-32b89a27f457>:17: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences_batch), len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8278\n",
      "\n",
      "Generating text after epoch: 0\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7711\n",
      "\n",
      "Generating text after epoch: 1\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7544\n",
      "\n",
      "Generating text after epoch: 2\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7451\n",
      "\n",
      "Generating text after epoch: 3\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7390\n",
      "\n",
      "Generating text after epoch: 4\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7350\n",
      "\n",
      "Generating text after epoch: 5\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7321\n",
      "\n",
      "Generating text after epoch: 6\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7299\n",
      "\n",
      "Generating text after epoch: 7\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7277\n",
      "\n",
      "Generating text after epoch: 8\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7264\n",
      "\n",
      "Generating text after epoch: 9\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7247\n",
      "\n",
      "Generating text after epoch: 10\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7235\n",
      "\n",
      "Generating text after epoch: 11\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7235\n",
      "\n",
      "Generating text after epoch: 12\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7229\n",
      "\n",
      "Generating text after epoch: 13\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7229\n",
      "\n",
      "Generating text after epoch: 14\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7226\n",
      "\n",
      "Generating text after epoch: 15\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7225\n",
      "\n",
      "Generating text after epoch: 16\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7220\n",
      "\n",
      "Generating text after epoch: 17\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7216\n",
      "\n",
      "Generating text after epoch: 18\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.7233\n",
      "\n",
      "Generating text after epoch: 19\n",
      "Generating text after processing batch: 0\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"google         \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-d526e4961fb6>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Generated:  dwss              issn w              ameriha        e i              orn a              laoa t              oeaae           markota         pemar e \n",
      "\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8628\n",
      "\n",
      "Generating text after epoch: 0\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8562\n",
      "\n",
      "Generating text after epoch: 1\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8533\n",
      "\n",
      "Generating text after epoch: 2\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8503\n",
      "\n",
      "Generating text after epoch: 3\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8477\n",
      "\n",
      "Generating text after epoch: 4\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8485\n",
      "\n",
      "Generating text after epoch: 5\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8471\n",
      "\n",
      "Generating text after epoch: 6\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8454\n",
      "\n",
      "Generating text after epoch: 7\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8452\n",
      "\n",
      "Generating text after epoch: 8\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8454\n",
      "\n",
      "Generating text after epoch: 9\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8445\n",
      "\n",
      "Generating text after epoch: 10\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8443\n",
      "\n",
      "Generating text after epoch: 11\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8443\n",
      "\n",
      "Generating text after epoch: 12\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8432\n",
      "\n",
      "Generating text after epoch: 13\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8433\n",
      "\n",
      "Generating text after epoch: 14\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8432\n",
      "\n",
      "Generating text after epoch: 15\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8420\n",
      "\n",
      "Generating text after epoch: 16\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8430\n",
      "\n",
      "Generating text after epoch: 17\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8417\n",
      "\n",
      "Generating text after epoch: 18\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8411\n",
      "\n",
      "Generating text after epoch: 19\n",
      "Generating text after processing batch: 1\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"google         \"\n",
      "...Generated:  i f              iid            a t              yonieo a       e x              ecdn           dcono r              lateria        toliase o        \n",
      "\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9140\n",
      "\n",
      "Generating text after epoch: 0\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9094\n",
      "\n",
      "Generating text after epoch: 1\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9089\n",
      "\n",
      "Generating text after epoch: 2\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9055\n",
      "\n",
      "Generating text after epoch: 3\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9044\n",
      "\n",
      "Generating text after epoch: 4\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9044\n",
      "\n",
      "Generating text after epoch: 5\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9037\n",
      "\n",
      "Generating text after epoch: 6\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9040\n",
      "\n",
      "Generating text after epoch: 7\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9021\n",
      "\n",
      "Generating text after epoch: 8\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9021\n",
      "\n",
      "Generating text after epoch: 9\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9010\n",
      "\n",
      "Generating text after epoch: 10\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9016\n",
      "\n",
      "Generating text after epoch: 11\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9005\n",
      "\n",
      "Generating text after epoch: 12\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9005\n",
      "\n",
      "Generating text after epoch: 13\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8992\n",
      "\n",
      "Generating text after epoch: 14\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8989\n",
      "\n",
      "Generating text after epoch: 15\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8998\n",
      "\n",
      "Generating text after epoch: 16\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8979\n",
      "\n",
      "Generating text after epoch: 17\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.8998\n",
      "\n",
      "Generating text after epoch: 18\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9001\n",
      "\n",
      "Generating text after epoch: 19\n",
      "Generating text after processing batch: 2\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"google         \"\n",
      "...Generated:  pfnc3            vyred s              uibd n              aioauae        p o              uailae         s a              ert a              eip n   \n",
      "\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9625\n",
      "\n",
      "Generating text after epoch: 0\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9592\n",
      "\n",
      "Generating text after epoch: 1\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9563\n",
      "\n",
      "Generating text after epoch: 2\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9556\n",
      "\n",
      "Generating text after epoch: 3\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9533\n",
      "\n",
      "Generating text after epoch: 4\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9502\n",
      "\n",
      "Generating text after epoch: 5\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9522\n",
      "\n",
      "Generating text after epoch: 6\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9501\n",
      "\n",
      "Generating text after epoch: 7\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9512\n",
      "\n",
      "Generating text after epoch: 8\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9488\n",
      "\n",
      "Generating text after epoch: 9\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9479\n",
      "\n",
      "Generating text after epoch: 10\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9469\n",
      "\n",
      "Generating text after epoch: 11\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9456\n",
      "\n",
      "Generating text after epoch: 12\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9481\n",
      "\n",
      "Generating text after epoch: 13\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9477\n",
      "\n",
      "Generating text after epoch: 14\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9448\n",
      "\n",
      "Generating text after epoch: 15\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9423\n",
      "\n",
      "Generating text after epoch: 16\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9430\n",
      "\n",
      "Generating text after epoch: 17\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9440\n",
      "\n",
      "Generating text after epoch: 18\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9439\n",
      "\n",
      "Generating text after epoch: 19\n",
      "Generating text after processing batch: 3\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"google         \"\n",
      "...Generated:  oeaisoit       d r              optolies       utse v              plrcreut         a n              oaloamh        l g              aolinnor        \n",
      "\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9933\n",
      "\n",
      "Generating text after epoch: 0\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9894\n",
      "\n",
      "Generating text after epoch: 1\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9859\n",
      "\n",
      "Generating text after epoch: 2\n",
      "3811/3907 [============================>.] - ETA: 0s - loss: 1.9857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9819\n",
      "\n",
      "Generating text after epoch: 4\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9815\n",
      "\n",
      "Generating text after epoch: 5\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9807\n",
      "\n",
      "Generating text after epoch: 6\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9804\n",
      "\n",
      "Generating text after epoch: 7\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9787\n",
      "\n",
      "Generating text after epoch: 8\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9798\n",
      "\n",
      "Generating text after epoch: 9\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9767\n",
      "\n",
      "Generating text after epoch: 10\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9756\n",
      "\n",
      "Generating text after epoch: 11\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9780\n",
      "\n",
      "Generating text after epoch: 12\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9740\n",
      "\n",
      "Generating text after epoch: 13\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9750\n",
      "\n",
      "Generating text after epoch: 14\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9741\n",
      "\n",
      "Generating text after epoch: 15\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9743\n",
      "\n",
      "Generating text after epoch: 16\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9732\n",
      "\n",
      "Generating text after epoch: 17\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9736\n",
      "\n",
      "Generating text after epoch: 18\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 1.9727\n",
      "\n",
      "Generating text after epoch: 19\n",
      "Generating text after processing batch: 4\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"google         \"\n",
      "...Generated:  oabia i              eataiao             iant             taoanpoant t              alsao a              ewpc           i b              eaaln       \n",
      "\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0221\n",
      "\n",
      "Generating text after epoch: 0\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0181\n",
      "\n",
      "Generating text after epoch: 1\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0172\n",
      "\n",
      "Generating text after epoch: 2\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0147\n",
      "\n",
      "Generating text after epoch: 3\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0154\n",
      "\n",
      "Generating text after epoch: 4\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0107\n",
      "\n",
      "Generating text after epoch: 5\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0105\n",
      "\n",
      "Generating text after epoch: 6\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0112\n",
      "\n",
      "Generating text after epoch: 7\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0122\n",
      "\n",
      "Generating text after epoch: 8\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0103\n",
      "\n",
      "Generating text after epoch: 9\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0102\n",
      "\n",
      "Generating text after epoch: 10\n",
      " 841/3907 [=====>........................] - ETA: 26s - loss: 2.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0103\n",
      "\n",
      "Generating text after epoch: 12\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0090\n",
      "\n",
      "Generating text after epoch: 13\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0092\n",
      "\n",
      "Generating text after epoch: 14\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0098\n",
      "\n",
      "Generating text after epoch: 15\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0073\n",
      "\n",
      "Generating text after epoch: 16\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0078\n",
      "\n",
      "Generating text after epoch: 17\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0084\n",
      "\n",
      "Generating text after epoch: 18\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0070\n",
      "\n",
      "Generating text after epoch: 19\n",
      "Generating text after processing batch: 5\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"google         \"\n",
      "...Generated:  aeeiao          a m              eeileoi o              aarsareiar      oafoat a              cemel          aokem a  . s              iovar         \n",
      "\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0564\n",
      "\n",
      "Generating text after epoch: 0\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0477\n",
      "\n",
      "Generating text after epoch: 1\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0446\n",
      "\n",
      "Generating text after epoch: 2\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0391\n",
      "\n",
      "Generating text after epoch: 3\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0367\n",
      "\n",
      "Generating text after epoch: 4\n",
      " 877/3907 [=====>........................] - ETA: 26s - loss: 2.0334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0274\n",
      "\n",
      "Generating text after epoch: 11\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0272\n",
      "\n",
      "Generating text after epoch: 12\n",
      "3907/3907 [==============================] - 35s 9ms/step - loss: 2.0251\n",
      "\n",
      "Generating text after epoch: 13\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0236\n",
      "\n",
      "Generating text after epoch: 14\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0240\n",
      "\n",
      "Generating text after epoch: 15\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0222\n",
      "\n",
      "Generating text after epoch: 16\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0220\n",
      "\n",
      "Generating text after epoch: 17\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0232\n",
      "\n",
      "Generating text after epoch: 18\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0204\n",
      "\n",
      "Generating text after epoch: 19\n",
      "Generating text after processing batch: 6\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"google         \"\n",
      "...Generated:  goaco t              ejsn m              eotmr          refeoter         eele           iiemse         asadae           eoaiaa o              uiifr  \n",
      "\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0521\n",
      "\n",
      "Generating text after epoch: 0\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0503\n",
      "\n",
      "Generating text after epoch: 1\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0470\n",
      "\n",
      "Generating text after epoch: 2\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0467\n",
      "\n",
      "Generating text after epoch: 3\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0438\n",
      "\n",
      "Generating text after epoch: 4\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0431\n",
      "\n",
      "Generating text after epoch: 5\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0412\n",
      "\n",
      "Generating text after epoch: 6\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0417\n",
      "\n",
      "Generating text after epoch: 7\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0398\n",
      "\n",
      "Generating text after epoch: 8\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0399\n",
      "\n",
      "Generating text after epoch: 9\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0404\n",
      "\n",
      "Generating text after epoch: 10\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0409\n",
      "\n",
      "Generating text after epoch: 11\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0405\n",
      "\n",
      "Generating text after epoch: 12\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0400\n",
      "\n",
      "Generating text after epoch: 13\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0383\n",
      "\n",
      "Generating text after epoch: 14\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0395\n",
      "\n",
      "Generating text after epoch: 15\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0405\n",
      "\n",
      "Generating text after epoch: 16\n",
      "3907/3907 [==============================] - 34s 9ms/step - loss: 2.0385\n",
      "\n",
      "Generating text after epoch: 17\n",
      " 865/3907 [=====>........................] - ETA: 26s - loss: 2.0293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "total_data = 4000000\n",
    "batch_size = 500000\n",
    "current_index = 0 \n",
    "\n",
    "while current_index < total_data:\n",
    "    # Get the next batch of data\n",
    "    sentences_batch = sentences[current_index:current_index + batch_size]\n",
    "    next_chars_batch = next_chars[current_index:current_index + batch_size]\n",
    "\n",
    "    # Initialize x and y for the current batch\n",
    "    x = np.zeros((len(sentences_batch), max_length, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences_batch), len(chars)), dtype=np.bool)\n",
    "\n",
    "    # Tokenize the current batch\n",
    "    for i, sentence in enumerate(sentences_batch):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars_batch[i]]] = 1\n",
    "\n",
    "    # Here you can perform training with the current batch if desired\n",
    "    epochs = 20\n",
    "    batch_sizes = 128\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.fit(x, y, batch_size=batch_sizes, epochs=1)\n",
    "        print()\n",
    "        print(\"Generating text after epoch: %d\" % epoch)\n",
    "        \n",
    "        if epoch == epochs - 1:  # Generate text after the last epoch of each batch\n",
    "            print(\"Generating text after processing batch:\", current_index // batch_size)\n",
    "            for diversity in [0.5]:\n",
    "                print(\"...Diversity:\", diversity)\n",
    "\n",
    "                generated = \"\"\n",
    "                seed_domain = \"google\"\n",
    "                padding_length = 15 - len(seed_domain)\n",
    "                sentence = seed_domain + \" \" * padding_length\n",
    "\n",
    "                print('...Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "                for i in range(150):\n",
    "                    x_pred = np.zeros((1, max_length, len(chars)))\n",
    "                    for t, char in enumerate(sentence):\n",
    "                        x_pred[0, t, char_indices[char]] = 1.0\n",
    "                    preds = model.predict(x_pred, verbose=0)[0]\n",
    "                    next_index = sample(preds, diversity)\n",
    "                    next_char = indices_char[next_index]\n",
    "                    sentence = sentence[1:] + next_char\n",
    "                    generated += next_char\n",
    "\n",
    "                print(\"...Generated:\", generated)\n",
    "                print()\n",
    "\n",
    "\n",
    "    # Update the index for the next batch\n",
    "    current_index += batch_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Ruta al archivo del modelo\n",
    "modelo_archivo = 'modelo_entrenado_tranco.h5'\n",
    "\n",
    "# Cargar el modelo\n",
    "model = load_model(modelo_archivo)\n",
    "\n",
    "\n",
    "# Suppose your trained model is stored in the variable 'model'\n",
    "model.save('trained_model_checkpoint.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz0123456789-._ \n",
      "Total chars: 40\n",
      "...Diversity: 0.5\n",
      "...Generated:  \n",
      "...Diversity: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-28a2624f0681>:31: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the file\n",
    "model = load_model('trained_model_checkpoint.h5')\n",
    "\n",
    "# Seed domain for generating text\n",
    "seed_domain = \"google\"\n",
    "padding_length = 15 - len(seed_domain)\n",
    "sentence = seed_domain + \" \" * padding_length\n",
    "\n",
    "generated = \"\"\n",
    "maxlen=15\n",
    "\n",
    "# Define the alphabet\n",
    "alphabet = string.ascii_lowercase + \"0123456789-._ \"\n",
    "print(alphabet)\n",
    "\n",
    "# Get unique characters from the alphabet\n",
    "chars = sorted(list(set(alphabet)))\n",
    "print(\"Total chars:\", len(chars))\n",
    "\n",
    "# Create dictionaries for character to index and index to character mappings\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Define the sampling function\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "if len(sentence) < 15:\n",
    "    sentence = sentence.ljust(15)\n",
    "\n",
    "for diversity in [0.5]:\n",
    "    print(\"...Diversity:\", diversity)\n",
    "\n",
    "print(\"...Generated: \", generated)\n",
    "print(\"...Diversity:\", diversity)\n",
    "\n",
    "# Generate domain names\n",
    "for i in range(150000):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.0\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_index = sample(preds, diversity)\n",
    "    next_char = indices_char[next_index]\n",
    "    sentence = sentence[1:] + next_char\n",
    "    generated += next_char\n",
    "    \n",
    "    #if i % 1000 == 0:  # Check if i is a multiple of 1000\n",
    "        #print(\"Value of i:\", i)\n",
    "\n",
    "#print(\"...Generated: \", generated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Length of each segment\n",
    "segment_length = 15\n",
    "\n",
    "# Calculate the number of segments\n",
    "num_segments = len(generated) // segment_length\n",
    "\n",
    "# Create a list to store the segments\n",
    "segments = [generated[i:i + segment_length] for i in range(0, len(generated), segment_length)]\n",
    "\n",
    "# Create the \"Test\" DataFrame\n",
    "df2 = pd.DataFrame({\"Segment\": segments})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fix_domain(segment):\n",
    "    # Remove leading spaces\n",
    "    fixed_segment = segment.strip()\n",
    "\n",
    "    # Find the first space after encountering letters and cut there\n",
    "    for i, char in enumerate(fixed_segment):\n",
    "        if char.isspace() and any(c.isalpha() for c in fixed_segment[:i]):\n",
    "            fixed_segment = fixed_segment[:i]\n",
    "            break\n",
    "\n",
    "    return fixed_segment\n",
    "\n",
    "# Concatenate all characters of each row without spaces\n",
    "df2[\"Joined_Segment\"] = df2[\"Segment\"].str.replace(\" \", \"\")\n",
    "\n",
    "# Apply the fix_domain function to the \"Joined_Segment\" column\n",
    "df2[\"Fixed_Segment\"] = df2[\"Joined_Segment\"].apply(fix_domain)\n",
    "\n",
    "# Drop the \"Joined_Segment\" column if no longer needed\n",
    "df2.drop(columns=[\"Joined_Segment\"], inplace=True)\n",
    "df2.drop(columns=[\"Segment\"], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['com', 'ru', 'net', 'org', 'de', 'co.uk', 'top', 'com.br', 'info', 'cn', 'nl', 'xyz', 'fr', 'com.au', 'ca', 'it', 'jp', 'io', 'pl', 'co', 'ch', 'dk', 'co.jp', 'eu', 'biz', 'in', 'us', 'ir', 'online', 'se', 'es', 'be', 'cz', 'site', 'at', 'cc', 'club', 'ro', 'com.cn', 'buzz', 'pro', 'com.tr', 'no', 'co.kr', 'fi', 'co.nz', 'tv', 'hu', 'me', 'shop']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have your dataframe df loaded\n",
    "\n",
    "# Calculate the frequency of each TLD\n",
    "tld_frequency = df['TLD'].value_counts()\n",
    "\n",
    "# Select the top 50 most common TLDs\n",
    "top_50_tld = tld_frequency.head(50)\n",
    "\n",
    "# Convert the result into a list\n",
    "TLD = top_50_tld.index.tolist()\n",
    "\n",
    "# Now TLD contains the top 50 most common TLDs\n",
    "print(TLD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  DGA\n",
      "0         iisy.com.au\n",
      "1     oolwsnrt.online\n",
      "2             ma.club\n",
      "3      bsoevell.co.jp\n",
      "4       oittar.com.au\n",
      "...               ...\n",
      "9995        pselhh.cc\n",
      "9996      sida.com.au\n",
      "9997       ct-lowd.se\n",
      "9998            ae.co\n",
      "9999      iaassuac.it\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you already have your dataframe df2 loaded and you have the variable TLD\n",
    "\n",
    "# Randomly choose a TLD from the TLD list for each domain in Fixed_Segment\n",
    "random_tld = np.random.choice(TLD, size=len(df2))\n",
    "\n",
    "# Concatenate the random TLD to the domain name\n",
    "df2['DGA'] = df2['Fixed_Segment'] + '.' + random_tld\n",
    "df2.drop(columns=[\"Fixed_Segment\"], inplace=True)\n",
    "\n",
    "# Show the first few rows of the resulting dataframe\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a CSV file\n",
    "df2.to_csv('domain_genered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  DGA           domain          prob result\n",
      "0         iisy.com.au      iisy.com.au  1.667312e-03  legit\n",
      "1     oolwsnrt.online  oolwsnrt.online  9.577204e-01    dga\n",
      "2             ma.club          ma.club  6.073166e-13  legit\n",
      "3      bsoevell.co.jp   bsoevell.co.jp  1.726585e-05  legit\n",
      "4       oittar.com.au    oittar.com.au  4.726736e-10  legit\n",
      "...               ...              ...           ...    ...\n",
      "9995        pselhh.cc        pselhh.cc  1.000000e+00    dga\n",
      "9996      sida.com.au      sida.com.au  3.568834e-09  legit\n",
      "9997       ct-lowd.se       ct-lowd.se  1.672512e-10  legit\n",
      "9998            ae.co            ae.co  6.642495e-07  legit\n",
      "9999      iaassuac.it      iaassuac.it  9.959363e-01    dga\n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Define the function to fetch data from the API\n",
    "def fetch_api_data(domain):\n",
    "    url = f\"http://172.17.0.1:8085/labin/{domain}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "# Create a list of dictionaries with data from the API\n",
    "data_from_api = [fetch_api_data(domain) for domain in df2['DGA']]\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "api_df = pd.DataFrame(data_from_api)\n",
    "\n",
    "# Concatenate the original DataFrame with the API DataFrame\n",
    "result_labin = pd.concat([df2, api_df], axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(result_labin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  DGA           domain          prob result  Label  resultnum\n",
      "0         iisy.com.au      iisy.com.au  1.667312e-03  legit      1          0\n",
      "1     oolwsnrt.online  oolwsnrt.online  9.577204e-01    dga      1          1\n",
      "2             ma.club          ma.club  6.073166e-13  legit      1          0\n",
      "3      bsoevell.co.jp   bsoevell.co.jp  1.726585e-05  legit      1          0\n",
      "4       oittar.com.au    oittar.com.au  4.726736e-10  legit      1          0\n",
      "...               ...              ...           ...    ...    ...        ...\n",
      "9995        pselhh.cc        pselhh.cc  1.000000e+00    dga      1          1\n",
      "9996      sida.com.au      sida.com.au  3.568834e-09  legit      1          0\n",
      "9997       ct-lowd.se       ct-lowd.se  1.672512e-10  legit      1          0\n",
      "9998            ae.co            ae.co  6.642495e-07  legit      1          0\n",
      "9999      iaassuac.it      iaassuac.it  9.959363e-01    dga      1          1\n",
      "\n",
      "[10000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create the new column 'Label' and fill it with the string 'dga'\n",
    "result_labin['Label'] = 1\n",
    "\n",
    "# Create the column 'resultnum' with values 1 for 'dga' and 0 for 'legit'\n",
    "result_labin['resultnum'] = (result_labin['result'] == 'dga').astype(int)\n",
    "print(result_labin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[   0    0]\n",
      " [8352 1648]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.16      0.28     10000\n",
      "\n",
      "    accuracy                           0.16     10000\n",
      "   macro avg       0.50      0.08      0.14     10000\n",
      "weighted avg       1.00      0.16      0.28     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(result_labin['Label'], result_labin['resultnum'])\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate and display the classification metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(result_labin['Label'], result_labin['resultnum']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  DGA           domain   class  probability\n",
      "0         iisy.com.au      iisy.com.au  normal       0.0003\n",
      "1     oolwsnrt.online  oolwsnrt.online     dga       0.9837\n",
      "2             ma.club          ma.club  normal       0.0004\n",
      "3      bsoevell.co.jp   bsoevell.co.jp  normal       0.0045\n",
      "4       oittar.com.au    oittar.com.au  normal       0.0002\n",
      "...               ...              ...     ...          ...\n",
      "9995        pselhh.cc        pselhh.cc     dga       0.9989\n",
      "9996      sida.com.au      sida.com.au  normal       0.0002\n",
      "9997       ct-lowd.se       ct-lowd.se  normal       0.0000\n",
      "9998            ae.co            ae.co  normal       0.0027\n",
      "9999      iaassuac.it      iaassuac.it  normal       0.0158\n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_api_data(domain):\n",
    "    detector_ip = \"172.17.0.1\"  # Change to the IP address of the host or container where the DGA detector is hosted\n",
    "    detector_port = 8000  # Change to the port on which the DGA detector is listening\n",
    "    url = f\"http://{detector_ip}:{detector_port}/predict?domain={domain}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "# Create a list of dictionaries with data from the API\n",
    "data_from_api1 = [fetch_api_data(domain) for domain in df2['DGA']]\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "api_df1 = pd.DataFrame(data_from_api1)\n",
    "\n",
    "# Concatenate the original DataFrame with the API DataFrame\n",
    "result_df2 = pd.concat([df2, api_df1], axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(result_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  DGA           domain   class  probability  Label  resultnum\n",
      "0         iisy.com.au      iisy.com.au  normal       0.0003      1          0\n",
      "1     oolwsnrt.online  oolwsnrt.online     dga       0.9837      1          1\n",
      "2             ma.club          ma.club  normal       0.0004      1          0\n",
      "3      bsoevell.co.jp   bsoevell.co.jp  normal       0.0045      1          0\n",
      "4       oittar.com.au    oittar.com.au  normal       0.0002      1          0\n",
      "...               ...              ...     ...          ...    ...        ...\n",
      "9995        pselhh.cc        pselhh.cc     dga       0.9989      1          1\n",
      "9996      sida.com.au      sida.com.au  normal       0.0002      1          0\n",
      "9997       ct-lowd.se       ct-lowd.se  normal       0.0000      1          0\n",
      "9998            ae.co            ae.co  normal       0.0027      1          0\n",
      "9999      iaassuac.it      iaassuac.it  normal       0.0158      1          0\n",
      "\n",
      "[10000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create the new column 'Label' and fill it with the string 'dga'\n",
    "result_df2['Label'] = 1\n",
    "\n",
    "# Create the column 'resultnum' with values 1 for 'dga' and 0 for 'legit'\n",
    "result_df2['resultnum'] = (result_df2['class'] == 'dga').astype(int)\n",
    "print(result_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[   0    0]\n",
      " [9660  340]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.03      0.07     10000\n",
      "\n",
      "    accuracy                           0.03     10000\n",
      "   macro avg       0.50      0.02      0.03     10000\n",
      "weighted avg       1.00      0.03      0.07     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(result_df2['Label'], result_df2['resultnum'])\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate and display the classification metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(result_df2['Label'], result_df2['resultnum']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
